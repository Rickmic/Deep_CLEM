{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Training Data\n",
    "=====================\n",
    "\n",
    "For the generation of training data you need aligned pairs of fluorescence microscopic (FM) and electron microscopic (EM) images. The FM images must be saved in one directory and the EM images in another directory.<br/> <br/>\n",
    "At first import some python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import imagej\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import PIL\n",
    "import imageio.v2 as imageio\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from tifffile import imread\n",
    "from tifffile import imwrite\n",
    "from csbdeep.utils import plot_some\n",
    "from csbdeep.utils.tf import limit_gpu_memory\n",
    "from csbdeep.data import RawData, create_patches_reduced_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect python to ImageJ/Fiji and navigate back to the original notebook folder. Insert the **path to your Fiji** installation and make sure, that **Fiji is closed**. If Fiji is not closed problems with Fiji could occur. Alternatively, leave empty to download Fiji in the background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "ij = imagej.init('../Fiji.app/') # Insert path to your Fiji app\n",
    "os.chdir(basedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess fluorescence microscopic images\n",
    "\n",
    "\n",
    "For the next steps you need two directories. One **directory with the raw FM images** and one **directory for the processed FM images** as ground truth for the training process. The directory with the raw images should contain about 100 FM images as training data. The dimensions of this images could be variable. The directory for the processed FM images should be an empty directory to save processed images.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <br/>\n",
    "  Here is an example for an unprocessed image with the chromatin in the blue and green channel:\n",
    "  <img src=\"https://raw.githubusercontent.com/Rickmic/Deep_CLEM/assets/fluo_unprocessed.png\" width=\"300\"/> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for raw fluorescence microscopic images:\n",
    "GTdirectory = basedir + '/data/FM_raw/'\n",
    "\n",
    "# directory for processed fluorescence microscopic images:\n",
    "Xdirectory = basedir + '/data/FM/'\n",
    "#os.mkdir(Xdirectory) # uncomment if directory do not exist already"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, the FM image will be processed. In this step the image will be converted to a greyscale image and downsized to 256x256 pixels. If a RGB image was presented, the **blue channel will be extracted** (preset). If the chromatin signal is located in another channel, you have to specify the chromatin channel in the code cell below. After execution of this cell, the number of images in the directory with the raw FM images and in the directory with the processed FM images must be equal.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <br/>\n",
    "  This is an example for a processed image:\n",
    "  <img src=\"https://raw.githubusercontent.com/Rickmic/Deep_CLEM/assets/fluo_processed.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert RGB image or a z stack into a greyscale image:\n",
    "def StackRGB(shape, IM):\n",
    "    channel2 = shape[2]\n",
    "    if channel2 <=4: # image is a RGB image\n",
    "        channelofI = IM[:, :, 2] # change channel number if channel for correlation of \n",
    "        # light microscopic image differs 0 = red; 1 = green; 2 = blue\n",
    "    else: # image is a stack\n",
    "        channelofI = IM[0, :, :]\n",
    "    # return greyscale image:\n",
    "    return channelofI \n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None # avoid error message for extremely large images\n",
    "\n",
    "\n",
    "print('groundtruth--------------------------------------------------')\n",
    "for filename in os.listdir(GTdirectory): # loop over all files in the GTdirectory\n",
    "    if filename.endswith((\".png\", \".tif\", \".tiff\")): # check if file is an image\n",
    "        GTpath = os.path.join(GTdirectory, filename) \n",
    "        IM = imageio.imread(GTpath) # open image\n",
    "        dimension = IM.ndim\n",
    "        shape = IM.shape\n",
    "        if dimension >= 3: # RGB image or stack\n",
    "            channelofI = StackRGB(shape, IM)\n",
    "        else: # greyscale image\n",
    "            channelofI = IM\n",
    "        GT = channelofI\n",
    "        #GT = GT[:960, :] # uncomment if ground truth image should be cropped [y, x]\n",
    "        GT = cv2.resize(GT, dsize=(256, 256), interpolation=cv2.INTER_LINEAR) # resize image to 256x256\n",
    "        name, ext = os.path.splitext(filename) # split filename in name and extension (ext)\n",
    "        writepath = os.path.join(Xdirectory, name + '.tif')\n",
    "        imwrite(writepath, GT) # save image as .tif\n",
    "        \n",
    "        # print feedback\n",
    "        print(filename + ': processed')\n",
    "        text = 'shape: %s to  %s' % (shape, GT.shape)\n",
    "        print(text)\n",
    "        print(' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess electron microscopic images\n",
    "\n",
    "For this step you have to specify again two directories. One **directory with the raw EM images** and one **directory for the processed EM images** as ground truth for the training process. The directory with the raw EM images should contain exactly the same number of images as the directory for the raw FM images. The dimensions and the name of each EM image should be the same as the corresponding FM image. The directory for the processed EM images should be an empty directory to save processed images.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <br/>\n",
    "  Here is an example for an unprocessed image:\n",
    "  <img src=\"https://raw.githubusercontent.com/Rickmic/Deep_CLEM/assets/sem_unprocessed.png\" width=\"300\" /> \n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for raw electron microscopic images:\n",
    "IPdirectory = basedir + '/data/EM_raw'\n",
    "\n",
    "# directory for processed electron microscopic images:\n",
    "Ydirectory = basedir + '/data/EM'\n",
    "#os.mkdir(Ydirectory) # comment out, if directory exists already"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step the EM image will be processed. Therefore the histogramm will be equalized. The image will be converted in a greyscale image and downsized to 256x256 pixels. If a RGB image was presented, the red channel will be extracted (preset). If the chromatin signal is in another channel located, you have to specify this channel in the code cell below. After execution of this cell the number of images in the directory with the raw EM images and in the directory with the processed images must be equal.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <br/>\n",
    "    This is an example for a processed image with histogram equalization:\n",
    "  <img src=\"https://raw.githubusercontent.com/Rickmic/Deep_CLEM/assets/sem_processed.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert RGB image or a z stack into a greyscale image:\n",
    "def StackRGB(shape, IM):\n",
    "    channel2 = shape[2]\n",
    "    if channel2 <=4: # image is a RGB image\n",
    "        channelofI = IM[:, :, 2] # change channel number if channel for correlation of\n",
    "        # electron microscopic image differs 0 = red; 1 = green; 2 = blue\n",
    "    else: # image is a stack\n",
    "        channelofI = IM [0, :, :]\n",
    "    # return greyscale image:\n",
    "    return channelofI\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None # avoid error message for extremely large images\n",
    "\n",
    "\n",
    "print('input--------------------------------------------------------')\n",
    "for filename in os.listdir(IPdirectory): # loop over all files in the GTdirectory\n",
    "    if filename.endswith((\".png\", \".tif\", \".tiff\")): # check if file is an image\n",
    "        print(filename)\n",
    "        IPpath = os.path.join(IPdirectory, filename) \n",
    "        \n",
    "        # equalize histogram with a imageJ macro:\n",
    "        macro = \"\"\"\n",
    "        @ String name\n",
    "        open(name);\n",
    "        run(\"Enhance Contrast...\", \"saturated=0.3 equalize\");\n",
    "        \"\"\"\n",
    "        args = {\n",
    "        'name': IPpath\n",
    "        }\n",
    "        ij.py.run_macro(macro, args)\n",
    "        IM = ij.WindowManager.getCurrentImage()\n",
    "        # ImagePlus object to numpy array\n",
    "        IM = ij.py.from_java(IM)\n",
    "        IM = IM.astype(np.uint8)\n",
    "        \n",
    "        dimension = IM.ndim\n",
    "        shape = IM.shape\n",
    "        if dimension >= 3: # RGB image or stack\n",
    "            channelofI = StackRGB(shape, IM.data)\n",
    "        else: # greyscale image\n",
    "            channelofI = IM.data\n",
    "        #channelofI = channelofI[:960, :] # uncomment if input image should be cropped [y, x]\n",
    "        channelofI = cv2.resize(channelofI, dsize=(256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "        IP = np.stack((channelofI, channelofI), axis = 0) # generate Z-stack for training process\n",
    "        name, ext = os.path.splitext(filename) # split filename in name and extension (ext)\n",
    "        writepath = os.path.join(Ydirectory, name + '.tif')\n",
    "        imwrite(writepath, IP) # save image as .tif\n",
    "        \n",
    "        # print feedback:\n",
    "        print(filename + ': processed')\n",
    "        text = 'shape: %s to  %s' % (shape, IP.shape)\n",
    "        print(text)\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate training dataset\n",
    "\n",
    "This part of the script is based on [a jupyter notebook](https://nbviewer.jupyter.org/url/csbdeep.bioimagecomputing.com/examples/denoising3D/1_datagen.ipynb).\n",
    "At first you need to specify two directories. One directory should contain all preprocessed EM images. This directory was normally created during the preprocessing step and contains only images with the dimension 2x256x256. Another directory should contain all preprocessed FM images. This images should have the dimensions 256x256. In this step it is very important, that the corresponding **EM and FM images** are named with **exactly the same name**. <br/> Furthermore you have to insert the path and filename where the processed training data should be saved. The filename should end with .npz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to a folder with preprocessed electron microscopic images:\n",
    "Ydirectory = basedir + '/data/EM/'\n",
    "# Path to a folder with preprocessed electron microscopic images:\n",
    "Xdirectory = basedir + '/data/FM/'\n",
    "# Path for the training data:\n",
    "train_npz = basedir + '/my_training_data.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create basepath, source_dirs and target_dir\n",
    "\n",
    "commonpath = os.path.commonpath([Ydirectory, Xdirectory])\n",
    "\n",
    "def getdirectory(directory):\n",
    "    if os.path.basename(directory) == '':\n",
    "        path = os.path.dirname(directory)\n",
    "        folder = os.path.basename(path)\n",
    "    else:\n",
    "        folder = os.path.basename(directory)\n",
    "    return(folder)\n",
    "\n",
    "directory = Ydirectory\n",
    "Yfolder = getdirectory(directory)\n",
    "\n",
    "directory = Xdirectory\n",
    "Xfolder = getdirectory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = RawData.from_folder (\n",
    "    basepath    = commonpath,\n",
    "    source_dirs = [Yfolder],\n",
    "    target_dir  = Xfolder,\n",
    "    axes        = 'ZYX',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, Y, XY_axes = create_patches_reduced_target (\n",
    "    raw_data            = raw_data,\n",
    "    patch_size          = (None,128,128),\n",
    "    n_patches_per_image = 16,\n",
    "    target_axes         = 'YX',\n",
    "    reduction_axes      = 'Z',\n",
    "    save_file           = train_npz,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready with preprocessing. If you wish, you can display with the next cells the dimensions of the training data and some generated training data pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of X   =\", X.shape)\n",
    "print(\"shape of Y   =\", Y.shape)\n",
    "print(\"axes  of X,Y =\", XY_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    sl = slice(8*i, 8*(i+1)), 0\n",
    "    plot_some(X[sl],Y[sl],title_list=[np.arange(sl[0].start,sl[0].stop)])\n",
    "    plt.show()\n",
    "None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
